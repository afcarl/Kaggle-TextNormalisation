{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neerjadoshi/anaconda2/envs/fastai/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import inflect\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from collections import defaultdict, Counter\n",
    "import feather\n",
    "from num2words import num2words \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_classify_train_data(np_file,csv_file):\n",
    "#     if os.path.exists(np_file) == True:\n",
    "#        temp = np.load(np_file)\n",
    "#        return temp['x_train'],temp['y_train'],temp['label']\n",
    "#     else:\n",
    "#         num_features = 9 #每个 word 取前 5 后 4 个字符来编码\n",
    "#         train=pd.read_csv(csv_file)\n",
    "#         tmp=pd.factorize(train['class'])\n",
    "#         y_train,label=tmp[0].astype(np.int8),tmp[1].values\n",
    "#         num_train=len(y_train)\n",
    "#         train['before']=train['before'].astype(np.str)\n",
    "#         x_train=np.zeros([num_train,num_features],np.int8)\n",
    "#         feature=np.zeros([num_train,7],np.int8)# 人工提取的特征\n",
    "#         list1=('a','e','i','o','u')# 元音\n",
    "#         list2=('+','-','*','//','%')# 数学运算符\n",
    "#         for word,row in zip(train['before'].values,range(num_train)):\n",
    "#             if(len(word)>=num_features):\n",
    "#                 for c,col in zip(word[:5],range(5)):\n",
    "#                     x_train[row,col]=ord(c)\n",
    "#                 for c,col in zip(word[-4:],range(5,9)):\n",
    "#                     x_train[row,col]=ord(c)\n",
    "#             else:\n",
    "#                 for c,col in zip(word,range(num_features)):\n",
    "#                     x_train[row,col]=ord(c)\n",
    "#             feature[row, 3] =len(word) # 统计字符串的长度\n",
    "#             dotflag=0\n",
    "#             for c in word:\n",
    "#                 if c.isdigit():feature[row,0]+=1# 统计数字的个数\n",
    "#                 if c.isupper():feature[row,1]+=1# 统计大写字母的个数\n",
    "#                 if c.isalnum()!=True:feature[row,2]+=1# 统计非字母和数字的个数\n",
    "#                 if c in list1:feature[row,4]+=1# 统计元音的个数\n",
    "#                 if c=='.': dotflag=1\n",
    "#                 elif dotflag==1:#  . 后面跟字母置 1 ，数字置 2，其他置 3\n",
    "#                     dotflag = 0\n",
    "#                     if c.isdigit():feature[row,5]+=10\n",
    "#                     elif c.isalpha():feature[row,5]+=100\n",
    "#                     else:feature[row,5]+=1000\n",
    "#                 if c in list2:feature[row,6]+=1# 统计数学运算符的个数\n",
    "\n",
    "#         # 掐头去尾，结合上文 2 单词，下文 1 个单词\n",
    "#         num_train-=3\n",
    "#         y_train=y_train[2:-1]\n",
    "#         x_train=np.concatenate((x_train[:-3],x_train[1:-2],x_train[2:-1],x_train[3:],feature[2:-1]),axis=1)\n",
    "#         np.savez(np_file,x_train=x_train, y_train=y_train, label=label)\n",
    "#         return x_train, y_train, label\n",
    "\n",
    "# def get_classify_test_data(np_file,csv_file):\n",
    "#     test=pd.read_csv(csv_file)\n",
    "#     if os.path.exists(np_file) == True:\n",
    "#        temp = np.load(np_file)\n",
    "#        x_test=temp['x_test']\n",
    "#     else:\n",
    "#         num_features = 9 #每个 word 取前 5 后 4 个字符来编码\n",
    "#         human_feature=7 #人工提取7个特征\n",
    "#         num_test=len(test)\n",
    "#         test['before']=test['before'].astype(np.str)\n",
    "#         x_test=np.zeros([num_test,num_features],np.int8)\n",
    "#         feature=np.zeros([num_test,human_feature],np.int8)# 人工提取的特征\n",
    "#         list1=('a','e','i','o','u')# 元音\n",
    "#         list2=('+','-','*','//','%')# 数学运算符\n",
    "#         for word,row in zip(test['before'].values,range(num_test)):\n",
    "#             if(len(word)>=num_features):\n",
    "#                 for c,col in zip(word[:5],range(5)):\n",
    "#                     x_test[row,col]=ord(c)\n",
    "#                 for c,col in zip(word[-4:],range(5,9)):\n",
    "#                     x_test[row,col]=ord(c)\n",
    "#             else:\n",
    "#                 for c,col in zip(word,range(num_features)):\n",
    "#                     x_test[row,col]=ord(c)\n",
    "#             feature[row, 3] =len(word) # 统计字符串的长度\n",
    "#             dotflag=0\n",
    "#             for c in word:\n",
    "#                 if c.isdigit():feature[row,0]+=1# 统计数字的个数\n",
    "#                 if c.isupper():feature[row,1]+=1# 统计大写字母的个数\n",
    "#                 if c.isalnum()!=True:feature[row,2]+=1# 统计非字母和数字的个数\n",
    "#                 if c in list1:feature[row,4]+=1# 统计元音的个数\n",
    "#                 if c=='.': dotflag=1\n",
    "#                 elif dotflag==1:#  . 后面跟字母置 1 ，数字置 2，其他置 3\n",
    "#                     dotflag = 0\n",
    "#                     if c.isdigit():feature[row,5]+=10\n",
    "#                     elif c.isalpha():feature[row,5]+=100\n",
    "#                     else:feature[row,5]+=1000\n",
    "#                 if c in list2:feature[row,6]+=1# 统计数学运算符的个数\n",
    "\n",
    "#         # 开头补上2个单词,结尾补上1个单词，结合上文 2 单词，下文 1 个单词\n",
    "#         x_test = np.concatenate((np.zeros([2,num_features],np.int8),x_test,np.zeros([1,num_features],np.int8)),axis=0)\n",
    "#         feature = np.concatenate((np.zeros([2,human_feature],np.int8),feature,np.zeros([1,human_feature],np.int8)),axis=0)\n",
    "#         x_test=np.concatenate((x_test[:-3],x_test[1:-2],x_test[2:-1],x_test[3:],feature[2:-1]),axis=1)\n",
    "#         np.savez(np_file,x_test=x_test)\n",
    "#     return test, x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__=='__main__':\n",
    "#     prehead=''\n",
    "#     train_data_csv='en_train.csv'\n",
    "#     classify_train_file='classify_train.npz'\n",
    "#     xgb_model='xgb_model.dat'\n",
    "#     test_data_csv='en_test.csv'\n",
    "#     classify_test_file='classify_test.npz'\n",
    "#     xgb_model2='xgb_model2.dat'\n",
    "#     classify_test_file2='classify_test2.npz'\n",
    "\n",
    "#     # 训练模型\n",
    "#     x_train,y_train,label=get_classify_train_data(prehead+classify_train_file,prehead+train_data_csv)\n",
    "#     print(x_train.shape)\n",
    "#     dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "#     watchlist = [(dtrain, 'train')]\n",
    "#     param = {\n",
    "#         'eta': 0.3,\n",
    "#         'max_depth':10,\n",
    "#         'objective':'multi:softmax',\n",
    "#         'num_class':len(label),\n",
    "#         'eval_metric':'merror',\n",
    "#         'subsample': 1,\n",
    "#         'colsample_bytree': 1,\n",
    "#         'silent':1,\n",
    "#         'seed':0,\n",
    "#     }\n",
    "#     num_boost_rounds=10\n",
    "#     model = xgb.train(param, dtrain, num_boost_rounds, watchlist,verbose_eval=1)\n",
    "#     print('save model ',xgb_model2)\n",
    "#     pickle.dump(model,open(xgb_model2,'wb'))# 保存模型\n",
    "#     del x_train,y_train\n",
    "#     #gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # xgb\n",
    "# params = {'eta': 0.1, 'max_depth': 4, 'subsample': 0.9, 'colsample_bytree': 0.9, \n",
    "#           'objective': 'binary:logistic', 'eval_metric': 'accuracy', 'silent': False}\n",
    "\n",
    "# X = train[['class', 'before']]\n",
    "# X['class'] = X['class'].astype('category')\n",
    "# X['before'] = X['before'].astype('category')\n",
    "# y = train['after'].values\n",
    "# #y = y.astype('category')\n",
    "\n",
    "# test['class'] = test['class'].astype('category')\n",
    "# test['before'] = test['before'].astype('category')\n",
    "\n",
    "# sub = (test.sentence_id.astype(str) + '_' + test.token_id.astype(str)).to_frame()\n",
    "# sub['target']=''\n",
    "\n",
    "# sub_train = (train.sentence_id.astype(str) + '_' + train.token_id.astype(str)).to_frame()\n",
    "# sub_train['target']=''\n",
    "# nrounds= 200 #10**6  # need to change to 2000\n",
    "# kfold = 5  # need to change to 5\n",
    "\n",
    "# d_train = xgb.DMatrix(X, y) \n",
    "# d_valid = xgb.DMatrix(test) \n",
    "# xgb_model = xgb.train(params, d_train, nrounds, early_stopping_rounds=10, \n",
    "#                        maximize=True, verbose_eval=10)\n",
    "# sub['target'] += xgb_model.predict(xgb.DMatrix(test[features].values), \n",
    "#                     ntree_limit=xgb_model.best_ntree_limit+50) / (kfold)\n",
    "\n",
    "# sub_train['target'] += xgb_model.predict(xgb.DMatrix(train[features].values), \n",
    "#                     ntree_limit=xgb_model.best_ntree_limit+50) / (kfold)\n",
    "\n",
    "# gc.collect()\n",
    "# sub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # 预测 test 上的 class\n",
    "#     #model = pickle.load(open(xgb_model2, \"rb\"))\n",
    "#     test,x_test=get_classify_test_data(prehead+classify_test_file,prehead+test_data_csv)\n",
    "#     print(x_test.shape)\n",
    "#     dtest = xgb.DMatrix(x_test)\n",
    "#     pred = model.predict(dtest)\n",
    "#     pred = [label[int(x)] for x in pred]\n",
    "#     test['class']=pred\n",
    "#     test.to_csv(os.path.join(prehead, 'test_pred_class.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test.head())\n",
    "# test['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sub.to_csv(base_path+'test_sub_xgb.csv', index=False)\n",
    "# sub_train.to_csv(base_path+'train_sub_xgb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = train[['class', 'before']]\n",
    "# X['class'] = X['class'].astype('category')\n",
    "# X['before'] = [''.join(str(ord(c)) for c in s) for s in X['before']]\n",
    "# y = train['after'].values\n",
    "# y = y.map(ord)\n",
    "\n",
    "# test['class'] = test['class'].astype('category')\n",
    "# test['before'] = test['before'].map(ord)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining dictionary, rules and running predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the train file, google dataset, test file with predicted classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('en_train.csv')\n",
    "test = pd.read_csv('test_pred_class.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = train.groupby(['before', 'after']).size()\n",
    "# d = d.reset_index().sort_values(0, ascending=False)\n",
    "# d = d.loc[d['before'].drop_duplicates(keep='first').index]\n",
    "# d = d.loc[d['before'] != d['after']]\n",
    "# d = d.set_index('before')['after'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(list)\n",
    "train_list = [(train.iloc[i,3],train.iloc[i,4]) for i in range(train.shape[0])]\n",
    "for k,v in train_list:\n",
    "    d[k].append(v)\n",
    "    \n",
    "train_dict = {}\n",
    "for key in d:\n",
    "    c = Counter(d[key]).most_common(1)[0][0]\n",
    "    train_dict[key] = c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dict['.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# d1 = defaultdict(list)\n",
    "\n",
    "# google_dataset = os.listdir('en_with_types/')\n",
    "# for file in google_dataset:\n",
    "#     data = pd.read_csv('en_with_types/' + file, sep = '\\t', error_bad_lines= False, quoting=3)\n",
    "#     print(file)\n",
    "#     data = data[data.iloc[:,0] != 'PUNCT']\n",
    "#     data = data[data.iloc[:,0] != 'ELECTRONIC']    \n",
    "#     data = data[data.iloc[:,0] != '<eos>']   \n",
    "#     data = data.drop(data.columns[0], axis=1)\n",
    "#     #print(data.head())\n",
    "    \n",
    "#     data_list = [(data.iloc[i,0],data.iloc[i,1]) for i in range(data.shape[0])]\n",
    "#     for k,v in data_list:\n",
    "#         #print(data_list)[1:10]\n",
    "#         #print(k)\n",
    "#         #print(v)\n",
    "#         d1[k].append(v)\n",
    "#         #print(d1[k])\n",
    "        \n",
    "# counter_dict = {}\n",
    "# for key in d1:\n",
    "#     c = Counter(d1[key]).most_common(1)[0][0]\n",
    "#     counter_dict[key] = c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# f = open(\"dict.pkl\",\"wb\")\n",
    "# pickle.dump(counter_dict,f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<self>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# f = open(\"dict.pkl\",\"wb\")\n",
    "# pickle.dump(counter_dict,f)\n",
    "# f.close()\n",
    "\n",
    "p1 = pickle.load(open('dict.pkl', 'rb'))\n",
    "\n",
    "p1['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# p = {} # scores is an empty dict already\n",
    "# target = 'dict.pkl'\n",
    "# if os.path.getsize(target) > 0:      \n",
    "#     with open(target, \"rb\") as f:\n",
    "#         unpickler = pickle.Unpickler(f)\n",
    "#         # if file is not empty scores will be equal\n",
    "#         # to the value unpickled\n",
    "#         p = unpickler.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rom_to_int(string):\n",
    "\n",
    "    table=[['M',1000],['CM',900],['D',500],['CD',400],['C',100],['XC',90],['L',50],['XL',40],['X',10],['IX',9],['V',5],['IV',4],['I',1]]\n",
    "    returnint=0\n",
    "    for pair in table:\n",
    "\n",
    "\n",
    "        continueyes=True\n",
    "\n",
    "        while continueyes:\n",
    "            if len(string)>=len(pair[0]):\n",
    "\n",
    "                if string[0:len(pair[0])]==pair[0]:\n",
    "                    returnint+=pair[1]\n",
    "                    string=string[len(pair[0]):]\n",
    "\n",
    "                else: continueyes=False\n",
    "            else: continueyes=False\n",
    "\n",
    "    return returnint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For classes:\n",
    "p = inflect.engine()\n",
    "def plain(x):\n",
    "    return x\n",
    "\n",
    "def punct(x):\n",
    "    return x\n",
    "\n",
    "def cardinal(x):\n",
    "    try:\n",
    "        if re.match('.*[A-Za-z]+.*', x):\n",
    "            return x\n",
    "        x = re.sub(',', '', x, count = 10)\n",
    "\n",
    "        if(re.match('.+\\..*', x)):\n",
    "            x = p.number_to_words(float(x))\n",
    "        elif re.match('\\..*', x): \n",
    "            x = p.number_to_words(float(x))\n",
    "            x = x.replace('zero ', '', 1)\n",
    "        else:\n",
    "            x = p.number_to_words(int(x))\n",
    "        x = x.replace('zero', 'o')    \n",
    "        x = re.sub('-', ' ', x, count=10)\n",
    "        x = re.sub(' and','',x, count = 10)\n",
    "        return x\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "def verbatim(x):\n",
    "    return(x)\n",
    "\n",
    "\n",
    "def date(x):\n",
    "    try:\n",
    "        x = re.sub('\\.','',x )\n",
    "        if re.match('^[0-9]+$', x):\n",
    "            return re.sub('-', ' ', p.number_to_words(int(x))) \n",
    "        elif re.match('.*[A-Za-z]+.*',x):\n",
    "            y = re.sub(',','',x)\n",
    "            y = y.split(' ')\n",
    "            result_string = 'the '\n",
    "            two_dig = [w for w in y if len(w) <= 2]\n",
    "            if len(two_dig)>0:\n",
    "                num = int(str(two_dig[0]))\n",
    "                num = re.sub('-', ' ',  num2words(num, ordinal=True))\n",
    "                result_string = result_string + num + ' of '\n",
    "            month = [w for w in y if re.match('^[A-Za-z]+$', w)]\n",
    "            result_string = result_string  + str(month[0])\n",
    "            y = [w for w in y if w not in month]\n",
    "            year = [w for w in y if len(w) == 4]\n",
    "            year1 = (str(year[0][0:2]))\n",
    "            year2 = (str(year[0][2:4]))\n",
    "            year1 = re.sub('-', ' ', p.number_to_words(int(year1)))\n",
    "            year2 = re.sub('-', ' ', p.number_to_words(int(year2)))\n",
    "            result_string = result_string + ' ' + year1 + ' ' + year2\n",
    "            return result_string\n",
    "        else:\n",
    "            result_string = 'the '\n",
    "            y = re.sub('-', ' ', x)\n",
    "            y = y.split(' ')\n",
    "            num = int(str(y[0]))\n",
    "            num = re.sub('-', ' ',  num2words(num, ordinal=True))\n",
    "            result_string = result_string + num + ' of '\n",
    "            month = y[1]\n",
    "            result_string = result_string  + str(month[0])\n",
    "            year = [w for w in y if len(w) == 4]\n",
    "            year1 = (str(year[0][0:2]))\n",
    "            year2 = (str(year[0][2:4]))\n",
    "            year1 = re.sub('-', ' ', p.number_to_words(int(year1)))\n",
    "            year2 = re.sub('-', ' ', p.number_to_words(int(year2)))\n",
    "            result_string = result_string + ' ' + year1 + ' ' + year2\n",
    "            return result_string\n",
    "    except:\n",
    "        return x\n",
    "    \n",
    "def measure(x):\n",
    "    try:\n",
    "        x = re.sub(',', '', count=10)\n",
    "        x = x.split(' ')\n",
    "        replacement = {'MB': 'megabyte', 'MW': 'megawatt','ft':'feet', 'km':'kilometers', 'mm': 'millimeters', 'ha':'hectares', '\"':'inches', 'cm':'centimeters', '/day' : 'per day', 'nm' : 'nanometers', '/s':'per second', 'm2':'square meters', 'km2': 'square kilometers', 'percent': 'percent'}\n",
    "        #Comprehensive list of all measures\n",
    "        replacement = {'\"': 'inches', \"'\": 'feet', 'km/s': 'kilometers per second', 'AU': 'units', 'BAR': 'bars', 'CM': 'centimeters', 'mm': 'millimeters', 'FT': 'feet', 'G': 'grams', \n",
    "     'GAL': 'gallons', 'GB': 'gigabytes', 'GHZ': 'gigahertz', 'HA': 'hectares', 'HP': 'horsepower', 'HZ': 'hertz', 'KM':'kilometers', 'km3': 'cubic kilometers',\n",
    "     'KA':'kilo amperes', 'KB': 'kilobytes', 'KG': 'kilograms', 'KHZ': 'kilohertz', 'KM²': 'square kilometers', 'KT': 'knots', 'KV': 'kilo volts', 'M': 'meters',\n",
    "      'KM2': 'square kilometers','Kw':'kilowatts', 'KWH': 'kilo watt hours', 'LB': 'pounds', 'LBS': 'pounds', 'MA': 'mega amperes', 'MB': 'megabytes',\n",
    "     'KW': 'kilowatts', 'MPH': 'miles per hour', 'MS': 'milliseconds', 'MV': 'milli volts', 'kJ':'kilojoules', 'km/h': 'kilometers per hour',  'V': 'volts', \n",
    "     'M2': 'square meters', 'M3': 'cubic meters', 'MW': 'megawatts', 'M²': 'square meters', 'M³': 'cubic meters', 'OZ': 'ounces',  'MHZ': 'megahertz', 'MI': 'miles',\n",
    "     'MB/S': 'megabytes per second', 'MG': 'milligrams', 'ML': 'milliliters', 'YD': 'yards', 'au': 'units', 'bar': 'bars', 'cm': 'centimeters', 'ft': 'feet', 'g': 'grams', \n",
    "     'gal': 'gallons', 'gb': 'gigabytes', 'ghz': 'gigahertz', 'ha': 'hectares', 'hp': 'horsepower', 'hz': 'hertz', 'kWh': 'kilo watt hours', 'ka': 'kilo amperes', 'kb': 'kilobytes', \n",
    "     'kg': 'kilograms', 'khz': 'kilohertz', 'km': 'kilometers', 'km2': 'square kilometers', 'km²': 'square kilometers', 'kt': 'knots','kv': 'kilo volts', 'kw': 'kilowatts', \n",
    "     'lb': 'pounds', 'lbs': 'pounds', 'm': 'meters', 'm2': 'square meters','m3': 'cubic meters', 'ma': 'mega amperes', 'mb': 'megabytes', 'mb/s': 'megabytes per second', \n",
    "     'mg': 'milligrams', 'mhz': 'megahertz', 'mi': 'miles', 'ml': 'milliliters', 'mph': 'miles per hour','ms': 'milliseconds', 'mv': 'milli volts', 'mw': 'megawatts', 'm²': 'square meters',\n",
    "     'm³': 'cubic meters', 'oz': 'ounces', 'v': 'volts', 'yd': 'yards', 'µg': 'micrograms', 'ΜG': 'micrograms', 'kg/m3': 'kilograms per meter cube'}\n",
    "        result_string = ''\n",
    "        if re.match('.*%$',x[0]):\n",
    "            x = re.sub('%','',x[0])\n",
    "            x = cardinal(x)\n",
    "            result_string = result_string + x + ' percent' \n",
    "        elif re.match('.*\\\"$',x[0]):\n",
    "            x = re.sub('\\\"','',x[0])\n",
    "            x = cardinal(x)\n",
    "            result_string = result_string + x + ' inches' \n",
    "        elif len(x)<2:\n",
    "            return x\n",
    "        elif re.match('.*ft$', x[0]):\n",
    "            x = re.sub('ft','',x[0])\n",
    "            x = cardinal(x)\n",
    "            result_string = result_string + x1 + ' ' + replacement['ft']\n",
    "        elif x[1] in replacement:\n",
    "            x1 = cardinal(x[0])\n",
    "\n",
    "            result_string = result_string + x1 + ' ' + replacement[x[1]] \n",
    "        else:\n",
    "            result_string = x\n",
    "        return(result_string)\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "def letters(x):\n",
    "    try:\n",
    "        x = re.sub('[^a-zA-Z]', '', x)\n",
    "        x = x.lower()\n",
    "        result_string = ''\n",
    "        for i in range(len(x)):\n",
    "            result_string = result_string + x[i] + ' '\n",
    "        return(result_string.strip())  \n",
    "    except:\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def decimal(x):\n",
    "    try:\n",
    "        x = re.sub(',', '', count=10)\n",
    "        x = x.split(' ')\n",
    "        if len(x) == 1:\n",
    "            result_string = cardinal(x[0])\n",
    "        else:\n",
    "            result_string = cardinal(x[0]) + ' ' + x[1]\n",
    "        return result_string   \n",
    "    except:\n",
    "        return x\n",
    "\n",
    "def ordinal(x):\n",
    "    try:\n",
    "        result_string = ''\n",
    "        x = x.replace(',', '')\n",
    "        x = x.replace('[\\.]$', '')\n",
    "        if re.match('^[0-9]+$',x):\n",
    "            x = num2words(int(x), ordinal=True)\n",
    "            return(x.replace('-', ' '))\n",
    "        if re.match('.*V|X|I|L|D',x):\n",
    "            if re.match('.*th|st|nd|rd',x):\n",
    "                x = x[0:len(x)-2]\n",
    "                x = rom_to_int(x)\n",
    "                result_string = re.sub('-', ' ',  num2words(x, ordinal=True))\n",
    "            else:\n",
    "                x = rom_to_int(x)\n",
    "                result_string = 'the '+ re.sub('-', ' ',  num2words(x, ordinal=True))\n",
    "        else:\n",
    "            x = x[0:len(x)-2]\n",
    "            result_string = re.sub('-', ' ',  num2words(float(x), ordinal=True))\n",
    "        return(result_string)  \n",
    "    except:\n",
    "        return x\n",
    "\n",
    "def electronic(x):\n",
    "    return(x)\n",
    "\n",
    "def address(x):\n",
    "    try:\n",
    "        x = re.sub('[^0-9a-zA-Z]+', '', x)\n",
    "        result_string = ''\n",
    "        for i in range(0,len(x)):\n",
    "            if re.match('[A-Z]|[a-z]',x[i]):\n",
    "                result_string = result_string + plain(x[i]).lower() + ' '\n",
    "            else:\n",
    "                result_string = result_string + cardinal(x[i]) + ' '\n",
    "                \n",
    "        return(result_string.strip())        \n",
    "    except:    \n",
    "        return(x)\n",
    "\n",
    "def telephone(x):\n",
    "    try:\n",
    "        result_string = ''\n",
    "        for i in range(0,len(x)):\n",
    "            if re.match('[0-9]+', x[i]):\n",
    "                result_string = result_string + cardinal(x[i]) + ' '\n",
    "            else:\n",
    "                result_string = result_string + 'sil '\n",
    "        return result_string.strip()    \n",
    "    except:    \n",
    "        return(x)\n",
    "\n",
    "def time(x):\n",
    "    return(x)\n",
    "\n",
    "def money(x):\n",
    "    try:\n",
    "        if re.match('^\\$', x):\n",
    "            x = x.replace('$','')\n",
    "            text = cardinal(x)\n",
    "            x = text + ' dollars'\n",
    "            return x.lower()\n",
    "\n",
    "        elif re.match('^£', x):\n",
    "            x = x.replace('£','')\n",
    "            text = cardinal(x)\n",
    "            x = text+ ' pounds'\n",
    "            return x.lower()   \n",
    "            \n",
    "        elif re.match('^€', x):\n",
    "            x = x.replace('€','')\n",
    "            text = cardinal(x)\n",
    "            x = text+ ' euros'\n",
    "            return x.lower()        \n",
    "    except:    \n",
    "        return(x)\n",
    "\n",
    "def fraction(x):\n",
    "    try:\n",
    "        y = x.split('/')\n",
    "        result_string = ''\n",
    "        y[0] = cardinal(y[0])\n",
    "        y[1] = ordinal(y[1])\n",
    "        if y[1] == 4:\n",
    "            result_string = y[0] + ' quarters'\n",
    "        else:    \n",
    "            result_string = y[0] + ' ' + y[1] + 's'\n",
    "        return(result_string)\n",
    "    except:    \n",
    "        return(x)\n",
    "    \n",
    "    \n",
    "def digit(x): \n",
    "    try:\n",
    "        x = re.sub('[^0-9]', '',x)\n",
    "        result_string = ''\n",
    "        for i in x:\n",
    "            result_string = result_string + cardinal(i) + ' '\n",
    "        result_string = result_string.strip()\n",
    "        return result_string\n",
    "    except:\n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ten thousand euros'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x = '€10,000'\n",
    "money(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "after = []\n",
    "for i in range(test.shape[0]):\n",
    "#    print(test.iloc[i,3])\n",
    "#     print(after)\n",
    "    if test.iloc[i,3] in train_dict.keys():\n",
    "        after.append(train_dict[test.iloc[i,3]])\n",
    "    elif test.iloc[i,3] in p1.keys() and test.iloc[i,3] != '-' and test.iloc[i,3] != '.' and test.iloc[i,3] != '\"' and test.iloc[i,3] != '/' and test.iloc[i,3] != '\\\\' and test.iloc[i,3] != ',':\n",
    "        if p1[test.iloc[i,3]] == '<self>':\n",
    "            after.append(test.iloc[i,3])\n",
    "        else:\n",
    "            after.append(p1[test.iloc[i,3]]) \n",
    "    else:    \n",
    "        class_name = test.iloc[i,4]\n",
    "        if class_name == 'PLAIN':\n",
    "            after.append(plain(test.iloc[i,3]))\n",
    "        elif class_name == 'PUNCT':\n",
    "            after.append(punct(test.iloc[i,3]))\n",
    "        elif class_name  == 'CARDINAL':\n",
    "            after.append(cardinal(test.iloc[i,3]))\n",
    "        elif class_name == 'VERBATIM':\n",
    "            after.append(verbatim(test.iloc[i,3]))\n",
    "        elif class_name == 'DATE':\n",
    "            after.append(date(test.iloc[i,3]))\n",
    "        elif class_name == 'MEASURE':\n",
    "            after.append(measure(test.iloc[i,3]))\n",
    "        elif class_name == 'LETTERS':\n",
    "            after.append(letters(test.iloc[i,3]))\n",
    "        elif class_name == 'DECIMAL':\n",
    "            after.append(decimal(test.iloc[i,3]))\n",
    "        elif class_name == 'ORDINAL':\n",
    "            after.append(ordinal(test.iloc[i,3]))\n",
    "        elif class_name == 'ELECTRONIC':\n",
    "            after.append(electronic(test.iloc[i,3]))\n",
    "        elif class_name == 'ADDRESS':\n",
    "            after.append(address(test.iloc[i,3]))\n",
    "        elif class_name == 'DIGIT':\n",
    "            after.append(digit(test.iloc[i,3]))\n",
    "        elif class_name == 'MONEY':\n",
    "            after.append(money(test.iloc[i,3]))\n",
    "        elif class_name == 'TIME':\n",
    "            after.append(time(test.iloc[i,3]))\n",
    "        elif class_name == 'TELEPHONE':\n",
    "            after.append(telephone(test.iloc[i,3]))\n",
    "        elif class_name == 'FRACTION':\n",
    "            after.append(fraction(test.iloc[i,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>before</th>\n",
       "      <th>class</th>\n",
       "      <th>after</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Another</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Another</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>religious</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>religious</td>\n",
       "      <td>0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>family</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>family</td>\n",
       "      <td>0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>is</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>is</td>\n",
       "      <td>0_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>of</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>of</td>\n",
       "      <td>0_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sentence_id  token_id     before  class      after   id\n",
       "0           0            0         0    Another  PLAIN    Another  0_0\n",
       "1           1            0         1  religious  PLAIN  religious  0_1\n",
       "2           2            0         2     family  PLAIN     family  0_2\n",
       "3           3            0         3         is  PLAIN         is  0_3\n",
       "4           4            0         4         of  PLAIN         of  0_4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>before</th>\n",
       "      <th>class</th>\n",
       "      <th>after</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Another</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>Another</td>\n",
       "      <td>0_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>religious</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>religious</td>\n",
       "      <td>0_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>family</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>family</td>\n",
       "      <td>0_2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>is</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>is</td>\n",
       "      <td>0_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>of</td>\n",
       "      <td>PLAIN</td>\n",
       "      <td>of</td>\n",
       "      <td>0_4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  sentence_id  token_id     before  class      after   id\n",
       "0           0            0         0    Another  PLAIN    Another  0_0\n",
       "1           1            0         1  religious  PLAIN  religious  0_1\n",
       "2           2            0         2     family  PLAIN     family  0_2\n",
       "3           3            0         3         is  PLAIN         is  0_3\n",
       "4           4            0         4         of  PLAIN         of  0_4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['after'] = after\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id           after\n",
      "0             0_0         Another\n",
      "1             0_1       religious\n",
      "2             0_2          family\n",
      "3             0_3              is\n",
      "4             0_4              of\n",
      "5             0_5          Hazrat\n",
      "6             0_6          Sayyed\n",
      "7             0_7           Ahmad\n",
      "8             0_8             and\n",
      "9             0_9             his\n",
      "10           0_10          nephew\n",
      "11           0_11          Hazrat\n",
      "12           0_12           Abdul\n",
      "13           0_13             Haq\n",
      "14           0_14               .\n",
      "15            1_0             The\n",
      "16            1_1            free\n",
      "17            1_2          webapp\n",
      "18            1_3   functionality\n",
      "19            1_4        contains\n",
      "20            1_5  advertisements\n",
      "21            1_6          geared\n",
      "22            1_7              to\n",
      "23            1_8           small\n",
      "24            1_9      businesses\n",
      "25           1_10               .\n",
      "26            2_0         Kuklick\n",
      "27            2_1               ,\n",
      "28            2_2               p\n",
      "29            2_3               .\n",
      "...           ...             ...\n",
      "1088534  69998_21            nine\n",
      "1088535  69998_22          verses\n",
      "1088536  69998_23        two four\n",
      "1088537  69998_24     twenty five\n",
      "1088538  69998_25               ,\n",
      "1088539  69998_26      Revelation\n",
      "1088540  69998_27         chapter\n",
      "1088541  69998_28           seven\n",
      "1088542  69998_29           verse\n",
      "1088543  69998_30            nine\n",
      "1088544  69998_31               )\n",
      "1088545  69998_32               .\n",
      "1088546   69999_0              In\n",
      "1088547   69999_1        contrast\n",
      "1088548   69999_2               ,\n",
      "1088549   69999_3        assembly\n",
      "1088550   69999_4       languages\n",
      "1088551   69999_5             are\n",
      "1088552   69999_6      considered\n",
      "1088553   69999_7             low\n",
      "1088554   69999_8           level\n",
      "1088555   69999_9         because\n",
      "1088556  69999_10            they\n",
      "1088557  69999_11             are\n",
      "1088558  69999_12            very\n",
      "1088559  69999_13           close\n",
      "1088560  69999_14              to\n",
      "1088561  69999_15         machine\n",
      "1088562  69999_16       languages\n",
      "1088563  69999_17               .\n",
      "\n",
      "[1088564 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test['id'] = test.sentence_id.astype(str) + '_' + test.token_id.astype(str)\n",
    "\n",
    "print(test[['id', 'after']])\n",
    "test[['id', 'after']].to_csv('output5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
